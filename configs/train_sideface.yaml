seed_everything: 2022

trainer:
  callbacks:
    - class_path: pytorch_lightning.callbacks.RichProgressBar
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val/fmeasure
        mode: max
        filename: checkpoint_{epoch:03d}-precision={val/precision:.3f}-recall={val/recall:.3f}-f1={val/fmeasure:.3f}
        auto_insert_metric_name: False
        verbose: True
        save_top_k: 1
        save_last: True
  benchmark: True
  detect_anomaly: True
  num_sanity_val_steps: 0
  strategy: dp
  check_val_every_n_epoch: 20
  accelerator: gpu
  devices: 1
  max_epochs: 1000

model:
  hparams:
    ROOT: data/data/complete/infos
    DATASETS_TRAIN: data/splits/train_sideface.txt
    DATASETS_VALID: data/splits/valid.txt
    DATASETS_TEST: data/splits/test.txt
    BATCH_SIZE: 64
    NUM_WORKERS: 4
    LR: 1e-4

    # DATA
    DATA:
      NUM_INPUT_DOF: 4
      NUM_OUTPUT_DOF: 6
      VOCAB_SIZE: 514
      NUM_VIEW: 3
      NUM_TYPE: 2
      MAX_INPUT_LENGTH: 300
      MAX_OUTPUT_LENGTH: 128
      NUM_BITS: 9

      AUG_RATIO: 0.1
      NOISE_RATIO: 0.15
      NOISE_LENGTH: 0.02

      SCALE: 1280
      MAX_THICKNESS: 50
      MIN_THICKNESS: 5
      MERGE_TOLERANCE: 5

    # IOU Matching
    THRESHOLD: 0.5

    TOKEN:
      END: 512
      PAD: 513

    MODEL:
      NUM_MODEL: 512
      NUM_HEAD: 8
      NUM_FEEDFORWARD: 1024
      DROPOUT: 0.2
      ACTIVATION: relu
      NORMALIZE_BEFORE: True
      NUM_ENCODER_LAYERS: 6
      NUM_DECODER_LAYERS: 6
